<!DOCTYPE html>
<html lang="en" dir="auto">

<head>
	<script>
	MathJax = {
	  tex: {
		inlineMath: [['$', '$'], ['\\(', '\\)']]
	  },
	  startup: {
		ready: () => {
		  MathJax.startup.defaultReady();
		  document.querySelectorAll("script[type='math/tex']").forEach((node) => {
			MathJax.tex2chtmlPromise(node.textContent, {display: false}).then((html) => {
			  node.parentNode.replaceChild(html, node);
			});
		  });
		}
	  }
	};
	</script>	

	<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>[test] Difference between encodec and descript audio codec | LIA&#39;log</title>
<meta name="keywords" content="localization-ko, test">
<meta name="description" content="Motivation During Dec., 2023, I&rsquo;v pretrain the VALL-E model for Korean. Specifically, the pretrained model is released at the huggingface, however, as the pronounciation of the model and voice cloning ability is somewhat low due to 2k hours (from one data source) of the training data. To improve further, a new model has been trained with 8k hours (from 3 data sources) of the data, however, it shows much lower performance compared with the prior model, even though the almost every setup are identical.">
<meta name="author" content="">
<link rel="canonical" href="https://learnitanyway.github.io/posts/scrap/diff_in_encodec/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://learnitanyway.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://learnitanyway.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://learnitanyway.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://learnitanyway.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://learnitanyway.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="[test] Difference between encodec and descript audio codec" />
<meta property="og:description" content="Motivation During Dec., 2023, I&rsquo;v pretrain the VALL-E model for Korean. Specifically, the pretrained model is released at the huggingface, however, as the pronounciation of the model and voice cloning ability is somewhat low due to 2k hours (from one data source) of the training data. To improve further, a new model has been trained with 8k hours (from 3 data sources) of the data, however, it shows much lower performance compared with the prior model, even though the almost every setup are identical." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://learnitanyway.github.io/posts/scrap/diff_in_encodec/" /><meta property="og:image" content="https://learnitanyway.github.io/images/papermod-cover.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-16T09:54:10+09:00" />
<meta property="article:modified_time" content="2024-01-16T09:54:10+09:00" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://learnitanyway.github.io/images/papermod-cover.png"/>

<meta name="twitter:title" content="[test] Difference between encodec and descript audio codec"/>
<meta name="twitter:description" content="Motivation During Dec., 2023, I&rsquo;v pretrain the VALL-E model for Korean. Specifically, the pretrained model is released at the huggingface, however, as the pronounciation of the model and voice cloning ability is somewhat low due to 2k hours (from one data source) of the training data. To improve further, a new model has been trained with 8k hours (from 3 data sources) of the data, however, it shows much lower performance compared with the prior model, even though the almost every setup are identical."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://learnitanyway.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "scrap",
      "item": "https://learnitanyway.github.io/posts/scrap/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "[test] Difference between encodec and descript audio codec",
      "item": "https://learnitanyway.github.io/posts/scrap/diff_in_encodec/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "[test] Difference between encodec and descript audio codec",
  "name": "[test] Difference between encodec and descript audio codec",
  "description": "Motivation During Dec., 2023, I\u0026rsquo;v pretrain the VALL-E model for Korean. Specifically, the pretrained model is released at the huggingface, however, as the pronounciation of the model and voice cloning ability is somewhat low due to 2k hours (from one data source) of the training data. To improve further, a new model has been trained with 8k hours (from 3 data sources) of the data, however, it shows much lower performance compared with the prior model, even though the almost every setup are identical.",
  "keywords": [
    "localization-ko", "test"
  ],
  "articleBody": "Motivation During Dec., 2023, I’v pretrain the VALL-E model for Korean. Specifically, the pretrained model is released at the huggingface, however, as the pronounciation of the model and voice cloning ability is somewhat low due to 2k hours (from one data source) of the training data. To improve further, a new model has been trained with 8k hours (from 3 data sources) of the data, however, it shows much lower performance compared with the prior model, even though the almost every setup are identical.\nMy hypothesis on the failure is that trains on 8k hours failed because the different dataset results in incosistant audio tokens. Let say we have the same audio file. If the volum of the audio changed, the audio tokens will be changed as well. Although the 2k hours of data has similar average volumn, 8k hours of data have difference in audio noise, sampling rate, and volum as well, which results in the different discrete audio tokens.\nTo check this, I’v first heck the differences in the audio files $\\rightarrow$ have clear difference, even the average volum are different over 10dB. Then I check the differences in the discrete token with different volumns through this. Furthermore, I’v check the performance of other discrete audio token method (dac).\nSimilarity of all tokens Similarity of the first tokens As shown above, even the volum changes 2.5dB, the token similarity has been reduced (0.4 for Encodec, and 0.7 for dac) which potentially reduces the performance of discrete audio prediction in VALL-E or Bark.\nNote For the audio token generation, the discrete autio encoding can be used With audio volum scale, tokens can vary which can lower the performance of autio token generation Possible solutions for this problem is Use of audio encoding methods that robust over noise, volume scaling, … Data agumentation (noise, volum… ) Joint training of encoding model and generation model ",
  "wordCount" : "314",
  "inLanguage": "en",
  "datePublished": "2024-01-16T09:54:10+09:00",
  "dateModified": "2024-01-16T09:54:10+09:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://learnitanyway.github.io/posts/scrap/diff_in_encodec/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "LIA'log",
    "logo": {
      "@type": "ImageObject",
      "url": "https://learnitanyway.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://learnitanyway.github.io/" accesskey="h" title="LIA&#39;log (Alt + H)">LIA&#39;log</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://learnitanyway.github.io/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://github.com/LearnItAnyway" title="Github">
                    <span>Github</span>&nbsp;
                    <svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round"
                        stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12">
                        <path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"></path>
                        <path d="M15 3h6v6"></path>
                        <path d="M10 14L21 3"></path>
                    </svg>
                </a>
            </li>
            <li>
                <a href="https://learnitanyway.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://learnitanyway.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://learnitanyway.github.io/posts/">Posts</a>&nbsp;»&nbsp;<a href="https://learnitanyway.github.io/posts/scrap/">scrap</a></div>
    <h1 class="post-title entry-hint-parent">
      [test] Difference between encodec and descript audio codec
    </h1>
    <div class="post-meta"><span title='2024-01-16 09:54:10 +0900 KST'>January 16, 2024</span>&nbsp;·&nbsp;2 min

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul><ul>
                <li>
                    <a href="#motivation" aria-label="Motivation">Motivation</a></li></ul>
                    
                <li>
                    <a href="#note" aria-label="Note">Note</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h3 id="motivation">Motivation<a hidden class="anchor" aria-hidden="true" href="#motivation">#</a></h3>
<p>During Dec., 2023, I&rsquo;v pretrain the <a href="">VALL-E</a> model for Korean. Specifically, the pretrained model is released at the <a href="https://huggingface.co/LearnItAnyway/vall-e_korean">huggingface</a>, however, as the pronounciation of the model and voice cloning ability is somewhat low due to 2k hours (from one data source) of the training data. To improve further, a new model has been trained with 8k hours (from 3 data sources) of the data, however, it shows much lower performance compared with the prior model, even though the almost every setup are identical.</p>
<p>My hypothesis on the failure is that trains on 8k hours failed because the different dataset results in <strong>incosistant audio tokens</strong>. Let say we have the same audio file. If the volum of the audio changed, the audio tokens will be changed as well. Although the 2k hours of data has similar average volumn, 8k hours of data have difference in audio noise, sampling rate, and volum as well, which results in the different discrete audio tokens.</p>
<p>To check this, I&rsquo;v first heck the differences in the audio files $\rightarrow$ have clear difference, even the average volum are different over 10dB.
Then I check the differences in the discrete token with different volumns <a href="/test_audio_token_difference.ipynb">through this</a>. Furthermore, I&rsquo;v check the performance of other discrete audio token method (<a href="https://github.com/descriptinc/descript-audio-codec">dac</a>).</p>
<ul>
<li>Similarity of all tokens
<img loading="lazy" src="/da_diff_all.png" alt=""  />
<img loading="lazy" src="static/da_diff_all.png" alt=""  />
</li>
<li>Similarity of the first tokens
<img loading="lazy" src="/da_diff_first.png" alt=""  />
<img loading="lazy" src="/static/da_diff_first.png" alt=""  />
</li>
</ul>
<p>As shown above, even the volum changes 2.5dB, the token similarity has been reduced (0.4 for Encodec, and 0.7 for dac) which potentially reduces the performance of discrete audio prediction in VALL-E or Bark.</p>
<h2 id="note">Note<a hidden class="anchor" aria-hidden="true" href="#note">#</a></h2>
<ul>
<li>For the audio token generation, the discrete autio encoding can be used
<ul>
<li>With audio volum scale, tokens can vary which can lower the performance of autio token generation</li>
<li>Possible solutions for this problem is
<ul>
<li>Use of audio encoding methods that robust over noise, volume scaling, &hellip;</li>
<li>Data agumentation (noise, volum&hellip; )</li>
<li>Joint training of encoding model and generation model</li>
</ul>
</li>
</ul>
</li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://learnitanyway.github.io/tags/localization-ko/">localization-ko</a></li>
      <li><a href="https://learnitanyway.github.io/tags/test/">test</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://learnitanyway.github.io/posts/scrap/rt-2/">
    <span class="title">« Prev</span>
    <br>
    <span>[scrap] Robotic Transformer 2</span>
  </a>
  <a class="next" href="https://learnitanyway.github.io/posts/scrap/awq/">
    <span class="title">Next »</span>
    <br>
    <span>[scrap] AWQ - activation-aware weight quantization</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://learnitanyway.github.io/">LIA&#39;log</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
